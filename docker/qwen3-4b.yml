version: '3.9'

services:
  qwen3-4b:
    image: ghcr.io/huggingface/text-generation-inference:sha-4cce843
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - MAX_INPUT_LENGTH=4096
      - MAX_TOTAL_TOKENS=16384
      - DTYPE=bfloat16
      - NUM_SHARD=1
    volumes:
      - /mnt/d/ft:/data
    ports:
      - "30007:80"
    command:
      - "--model-id"
      - "/data/Qwen3-4B-Instruct"
    deploy:
      resources:
        reservations:
          memory: 8g
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
